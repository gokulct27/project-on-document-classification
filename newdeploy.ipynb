{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aebaf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gokul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gokul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import docx2txt,textract\n",
    "import pdfplumber\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot  as plt\n",
    "import plotly.express as px\n",
    "stop=set(stopwords.words('english'))\n",
    "from pickle import load\n",
    "import pickle\n",
    "model=load(open('Randomforest.sav','rb'))\n",
    "vectors = pickle.load(open('tfidf.pkl','rb'))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da983cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = []\n",
    "\n",
    "def display(doc_file):\n",
    "    if doc_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "        resume.append(docx2txt.process(doc_file))\n",
    "    else :\n",
    "        with pdfplumber.open(doc_file) as pdf:\n",
    "            pages=pdf.pages[0]\n",
    "            resume.append(pages.extract_text())\n",
    "    return resume\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfd9d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    return \" \".join(lemma_words)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b158d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    menu = [\"Prediction page\",\"About\"]\n",
    "    choice = st.sidebar.selectbox(\"Menu\",menu)\n",
    "    html_temp = \"\"\"\n",
    "    <div style =\"background-color:red;padding:13px\">\n",
    "    <h1 style =\"color:black;text-align:center;\"> DOCUMENT CLASSIFICATION </h1>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    st.markdown(html_temp, unsafe_allow_html = True)\n",
    "    \n",
    "    \n",
    "    if choice == \"Prediction page\":\n",
    "        st.subheader(\"prediction app\")\n",
    "    upload_file = st.file_uploader('Hey,Upload Your Resume ',\n",
    "                                type= ['docx','pdf'],accept_multiple_files=True)\n",
    "    if st.button(\"Process\"):\n",
    "        for doc_file in upload_file:\n",
    "            if doc_file is not None:\n",
    "                file_details = {'filename':[doc_file.name],\n",
    "                               'filetype':doc_file.type.split('.')[-1].upper(),\n",
    "                               'filesize':str(doc_file.size)+' KB'}\n",
    "                file_type=pd.DataFrame(file_details)\n",
    "                st.write(file_type.set_index('filename'))\n",
    "                displayed=display(doc_file)\n",
    "              \n",
    "                cleaned=preprocess(display(doc_file))\n",
    "                predicted= model.predict(vectors.transform([cleaned]))\n",
    "\n",
    "                if int(predicted) == 0:\n",
    "                    st.header(\"The Resume Is From Peoplessoft Resumes\")\n",
    "                elif int(predicted) == 1:\n",
    "                    st.header(\"The Resume Is From SQL_Developer_Lightning _Insight \")\n",
    "                elif int(predicted) == 2:\n",
    "                    st.header(\"The Resume Is From  React Js Developers \")\n",
    "                else:\n",
    "                    st.header(\"The Resume Is From  Workday Resumes \")\n",
    "    \n",
    "\n",
    "    elif choice == \"About\":\n",
    "        st.subheader(\"About\") \n",
    "        st.info(\"Document classification project from group5\")\n",
    "        st.info(\"Built with Streamlit\")\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baf401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d6958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e658737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48f552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
